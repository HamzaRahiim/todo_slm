[supervisord]
nodaemon=true
user=root

[program:ollama]
command=ollama serve
environment=OLLAMA_HOST=0.0.0.0
user=appuser
autostart=true
autorestart=true
stdout_logfile=/var/log/supervisor/ollama.log
stderr_logfile=/var/log/supervisor/ollama_error.log

[program:fastapi]
command=python3 main.py
directory=/app
user=appuser
autostart=true
autorestart=true
stdout_logfile=/var/log/supervisor/fastapi.log
stderr_logfile=/var/log/supervisor/fastapi_error.log
environment=ENVIRONMENT=production
[supervisord]
nodaemon=true

[program:ollama]
command=bash -c "curl -fsSL https://ollama.ai/install.sh | sh && ollama serve"
autorestart=true
priority=1

[program:app]
command=uvicorn main:app --host 0.0.0.0 --port 8000
autorestart=true
priority=2
